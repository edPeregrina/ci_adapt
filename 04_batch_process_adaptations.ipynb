{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is to batch process adaptations and analyse results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import configparser\n",
    "from pathlib import Path\n",
    "import pathlib\n",
    "from ci_adapt_utilities import *\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration with ini file (created running config.py)\n",
    "config_file=r'C:\\repos\\ci_adapt\\config_ci_adapt_test.ini'\n",
    "config = configparser.ConfigParser()\n",
    "config.read(config_file)\n",
    "\n",
    "# Define paths\n",
    "asset_data = config.get('DEFAULT', 'asset_data')\n",
    "# data_path = Path(pathlib.Path.home().parts[0]) / 'Data'\n",
    "data_path = Path(pathlib.Path(r'C:\\Users\\peregrin\\OneDrive - Stichting Deltares\\Documents\\PhD Daniel Shared\\Papers\\Paper 1 - Adaptation Framework\\Data\\test'))\n",
    "interim_data_path = data_path / 'interim' / 'collected_flood_runs'\n",
    "\n",
    "# Define costs for different transport modes\n",
    "average_train_load_tons = (896+1344+2160+1344+896+896+1344+1512+896+390)/10 # in Tons per train. Source: Kennisinstituut voor Mobiliteitsbeleid. 2023. Cost Figures for Freight Transport – final report\n",
    "average_train_cost_per_ton_km = (0.014+0.018+0.047+0.045)/4 # in Euros per ton per km. Source: Kennisinstituut voor Mobiliteitsbeleid. 2023. Cost Figures for Freight Transport – final report\n",
    "average_road_cost_per_ton_km = (0.395+0.375+0.246+0.203+0.138+0.153+0.125+0.103+0.122+0.099)/10 # in Euros per ton per km. Source: Kennisinstituut voor Mobiliteitsbeleid. 2023. Cost Figures for Freight Transport – final report\n",
    "\n",
    "# Define dictionaries of return periods and adaptation unit costs\n",
    "return_period_dict = {'_H_': 10,'_M_': 100,'_L_': 200}\n",
    "adaptation_unit_costs = {'fwall': 7408, #considering floodwall in Germany\n",
    "                         'viaduct': 36666, #considering viaduct cost\n",
    "                         'bridge': 40102}  #considering bridge of 10m deck width\n",
    "rp_spec_priority = set_rp_priorities(return_period_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675 assets loaded.\n",
      "Loaded data from baseline impact assessment\n",
      "Creating virtual graph...\n",
      "Success: only int type values\n"
     ]
    }
   ],
   "source": [
    "# Load data from baseline impact assessment\n",
    "assets_path = data_path / asset_data\n",
    "assets=preprocess_assets(assets_path)\n",
    "\n",
    "# Add buffer to assets to do area intersect and create dictionaries for quicker lookup\n",
    "# buffered_assets = ds.buffer_assets(assets)\n",
    "geom_dict = assets['geometry'].to_dict()\n",
    "\n",
    "print(f\"{len(assets)} assets loaded.\")\n",
    "\n",
    "shortest_paths = pickle.load(open(data_path / 'interim' / 'indirect_damages' / 'shortest_paths.pkl', 'rb'))\n",
    "disrupted_edges_by_basin = pickle.load(open(data_path / 'interim' / 'indirect_damages' / 'disrupted_edges_by_basin.pkl', 'rb'))\n",
    "graph_r0 = pickle.load(open(data_path / 'interim' / 'indirect_damages' / 'graph_0.pkl', 'rb'))\n",
    "disrupted_shortest_paths = pickle.load(open(data_path / 'interim' / 'indirect_damages' / 'disrupted_shortest_paths.pkl', 'rb'))\n",
    "event_impacts = pickle.load(open(data_path / 'interim' / 'indirect_damages' / 'event_impacts.pkl', 'rb'))\n",
    "full_flood_event=pickle.load(open(data_path / 'interim' / 'indirect_damages' / 'full_flood_event.pkl', 'rb'))\n",
    "all_disrupted_edges = pickle.load(open(data_path / 'interim' / 'indirect_damages' / 'all_disrupted_edges.pkl', 'rb'))\n",
    "collect_output = pickle.load(open(data_path / 'interim' / 'collected_flood_runs' / 'sample_collected_run.pkl', 'rb'))\n",
    "print('Loaded data from baseline impact assessment')\n",
    "graph_v0=create_virtual_graph(graph_r0)\n",
    "graph_v=graph_v0.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptations={}\n",
    "adaptations['baseline'] = {'l1_l2_adapt_path': None, 'added_links':[], 'l4_adapt_path': None}\n",
    "adaptations['l1_trib'] = {'l1_l2_adapt_path': data_path/r'input\\adaptations\\l1_tributary.geojson', 'added_links':[], 'l4_adapt_path': None}\n",
    "adaptations['l2_trib'] = {'l1_l2_adapt_path': data_path/r'input\\adaptations\\l2_tributary.geojson', 'added_links':[], 'l4_adapt_path': None}\n",
    "adaptations['l3_trib'] = {'l1_l2_adapt_path': None, 'added_links':[(4424116, 219651487), (219651487, 111997047)], 'l4_adapt_path': None}\n",
    "adaptations['l4_trib'] = {'l1_l2_adapt_path': None, 'added_links':[], 'l4_adapt_path': data_path/r'input\\adaptations\\l4_tributary.geojson'}\n",
    "# adaptations['l1_rhine'] = {'l1_l2_adapt_path': data_path/r'input\\adaptations\\l1_rhine.geojson', 'added_links':[], 'l4_adapt_path': None}\n",
    "# adaptations['l2_rhine'] = {'l1_l2_adapt_path': data_path/r'input\\adaptations\\l2_rhine.geojson', 'added_links':[], 'l4_adapt_path': None}\n",
    "# adaptations['l3_rhine'] = {'l1_l2_adapt_path': None, 'added_links':[(112044105, 110947346)], 'l4_adapt_path': None}\n",
    "# adaptations['l4_rhine'] = {'l1_l2_adapt_path': None, 'added_links':[], 'l4_adapt_path': data_path/r'input\\adaptations\\l4_rhine.geojson'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 5 scenarios:\n",
      "-  baseline\n",
      "-  l1_trib\n",
      "-  l2_trib\n",
      "-  l3_trib\n",
      "-  l4_trib\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9d13199ec194eb0bd62968679af86b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adaptation runs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b61f0423e824d6b92f65458686c4a5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing adapted damages by hazard map:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56951a8368474c858358e6f346d6a5b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing full flood events:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying adaptation:  fwall_nahe\n",
      "Level 1 adaptation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "528ea3107df54008851c682108f38d9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing adapted damages by hazard map:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "133d8178b6584230ab023bd1578ffb78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing full flood events:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying adaptation:  elev_nahe\n",
      "Level 2 adaptation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf65d6274f7d49ab9e9b9bd525d5d88a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing adapted damages by hazard map:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98610399bbf741db829051e1267f5629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing full flood events:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying adaptation: new connection between assets with osm_id  (4424116, 219651487)\n",
      "Level 3 adaptation\n",
      "Applying adaptation: new connection between assets with osm_id  (219651487, 111997047)\n",
      "Level 3 adaptation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6465f70fb494d619e315df6cf6e2e3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing adapted damages by hazard map:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebfaa9de28ab4b529ad32bbbbc2ed637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing full flood events:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying adaptation: reduced demand for routes:  [('node_682', 'node_684'), ('node_684', 'node_682'), ('node_260', 'node_387'), ('node_387', 'node_260'), ('node_387', 'node_434'), ('node_387', 'node_286'), ('node_434', 'node_387'), ('node_286', 'node_387')]\n",
      "Level 4 adaptation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efcc308ec4be47e3bc7ac84ef075785f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing adapted damages by hazard map:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f02097daa57b456f9553784819e4213a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing full flood events:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define empty dictionaries to store adaptation results\n",
    "direct_damages_adapted_dict = {}\n",
    "indirect_damages_adapted_dict = {}\n",
    "indirect_damages_adapted_full_dict = {}\n",
    "adaptation_costs={}\n",
    "adapted_assets_dict = {}\n",
    "\n",
    "# Print adaptations that will be run\n",
    "print(f\"Processing {len(adaptations)} scenarios:\")\n",
    "for adapt_id in adaptations.keys():\n",
    "    print('- ',adapt_id)\n",
    "\n",
    "for adapt_id in tqdm(adaptations.keys(), desc='Adaptation runs', total=len(adaptations)):\n",
    "    adaptations_df_path = data_path / 'interim' / 'adaptations' / f'{adapt_id}_adaptations.csv'\n",
    "\n",
    "    if adaptations_df_path.exists():\n",
    "        print(f\"Adaptation {adapt_id} already processed. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # reset variables\n",
    "    graph_v=graph_v0.copy()\n",
    "\n",
    "    # Load adaptations dictionary to the relevant variables\n",
    "    l1_l2_adapt_path = adaptations[adapt_id]['l1_l2_adapt_path']\n",
    "    added_links = adaptations[adapt_id]['added_links']  \n",
    "    l4_adapt_path = adaptations[adapt_id]['l4_adapt_path']\n",
    "\n",
    "    # Load adaptation data\n",
    "    if l1_l2_adapt_path is not None:\n",
    "        adapted_area = gpd.read_file(l1_l2_adapt_path).to_crs(3857)\n",
    "    else:\n",
    "        adapted_area = None\n",
    "    if l4_adapt_path is not None:\n",
    "        adapted_route_area = gpd.read_file(l4_adapt_path).to_crs(3857)\n",
    "    else:\n",
    "        adapted_route_area = None\n",
    "\n",
    "    # Apply adaptations\n",
    "    adapted_assets, adaptations_df, demand_reduction_dict, l3_adaptation_costs = apply_adaptations(adapted_area, assets, collect_output, interim_data_path, rp_spec_priority, adaptation_unit_costs, shortest_paths, graph_v, added_links, adapted_route_area)\n",
    "\n",
    "    # Calculate l1 adaptation costs\n",
    "    local_haz_path=data_path/r'Floods\\Germany\\basin_intersections'\n",
    "    l1_adaptation_costs=calculate_l1_costs(local_haz_path, interim_data_path, adapted_area, adaptation_unit_costs, adapted_assets) \n",
    "\n",
    "    # Run adapted damages for individual hazard maps\n",
    "    direct_damages_adapted, indirect_damages_adapted, adaptation_run_full, l2_adaptation_costs, overlay_assets_lists = run_adapted_damages(data_path, config_file, collect_output, disrupted_edges_by_basin, interim_data_path, assets, geom_dict, adapted_assets, adaptations_df, rp_spec_priority, adaptation_unit_costs, shortest_paths, graph_v, average_train_load_tons, average_train_cost_per_ton_km, average_road_cost_per_ton_km, demand_reduction_dict)\n",
    "\n",
    "    # Run adapted damages for full flood event\n",
    "    indirect_damages_adapted_full = calculate_indirect_dmgs_fullflood(full_flood_event, overlay_assets_lists, adaptation_run_full, assets, all_disrupted_edges, shortest_paths, graph_v, average_train_load_tons, average_train_cost_per_ton_km, average_road_cost_per_ton_km, demand_reduction_dict)\n",
    "\n",
    "\n",
    "    # Fill in missing values in dictionaries\n",
    "    for hazard_map in collect_output.keys():\n",
    "        if direct_damages_adapted[hazard_map]=={}:\n",
    "            direct_damages_adapted[hazard_map]=collect_output[hazard_map]\n",
    "        if indirect_damages_adapted[hazard_map]=={}:\n",
    "            indirect_damages_adapted[hazard_map]=event_impacts[hazard_map] if hazard_map in event_impacts.keys() else 0.0\n",
    "    \n",
    "    # Store results in dictionaries\n",
    "    direct_damages_adapted_dict[adapt_id] = direct_damages_adapted\n",
    "    indirect_damages_adapted_dict[adapt_id] = indirect_damages_adapted\n",
    "    indirect_damages_adapted_full_dict[adapt_id] = indirect_damages_adapted_full\n",
    "    adapted_assets_dict[adapt_id] = adapted_assets\n",
    "    adaptation_costs[adapt_id] = {'l1': l1_adaptation_costs, 'l2': l2_adaptation_costs, 'l3': l3_adaptation_costs}\n",
    "    adaptations_df.to_csv(data_path / 'interim' / 'adaptations' / f'{adapt_id}_adaptations.csv')\n",
    "\n",
    "    # break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>l1_trib</th>\n",
       "      <th>l2_trib</th>\n",
       "      <th>l3_trib</th>\n",
       "      <th>l4_trib</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'flood_DERP_RW_H_4326_2080430320': {2: (0, 0)...</td>\n",
       "      <td>{'flood_DERP_RW_H_4326_2080430320': {2: (0, 0)...</td>\n",
       "      <td>{'flood_DERP_RW_H_4326_2080430320': {2: (0.0, ...</td>\n",
       "      <td>{'flood_DERP_RW_H_4326_2080430320': {2: (0, 0)...</td>\n",
       "      <td>{'flood_DERP_RW_H_4326_2080430320': {2: (0, 0)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'flood_DERP_RW_H_4326_2080430320': 47481.4915...</td>\n",
       "      <td>{'flood_DERP_RW_H_4326_2080430320': 46107.8680...</td>\n",
       "      <td>{'flood_DERP_RW_H_4326_2080430320': 0, 'flood_...</td>\n",
       "      <td>{'flood_DERP_RW_H_4326_2080430320': -104509.06...</td>\n",
       "      <td>{'flood_DERP_RW_H_4326_2080430320': 46077.0756...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'flood_DERP_RW_H': 47481.49151079169, 'flood_...</td>\n",
       "      <td>{'flood_DERP_RW_H': 46107.86801530879, 'flood_...</td>\n",
       "      <td>{'flood_DERP_RW_H': 0, 'flood_DERP_RW_M': 0, '...</td>\n",
       "      <td>{'flood_DERP_RW_H': -104509.06271837394, 'floo...</td>\n",
       "      <td>{'flood_DERP_RW_H': 46077.0756865045, 'flood_D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Empty GeoDataFrame\n",
       "Columns: [osm_id, asset, na...</td>\n",
       "      <td>osm_id asset         name gauge   elec...</td>\n",
       "      <td>osm_id asset                name gauge...</td>\n",
       "      <td>Empty GeoDataFrame\n",
       "Columns: [osm_id, asset, na...</td>\n",
       "      <td>Empty GeoDataFrame\n",
       "Columns: [osm_id, asset, na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'l1': None, 'l2': {}, 'l3': {}}</td>\n",
       "      <td>{'l1': {0: 266240624.64660648}, 'l2': {}, 'l3'...</td>\n",
       "      <td>{'l1': {}, 'l2': {'flood_DERP_RW_H_4326_208043...</td>\n",
       "      <td>{'l1': None, 'l2': {}, 'l3': {(4424116, 219651...</td>\n",
       "      <td>{'l1': None, 'l2': {}, 'l3': {}}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            baseline  \\\n",
       "0  {'flood_DERP_RW_H_4326_2080430320': {2: (0, 0)...   \n",
       "1  {'flood_DERP_RW_H_4326_2080430320': 47481.4915...   \n",
       "2  {'flood_DERP_RW_H': 47481.49151079169, 'flood_...   \n",
       "3  Empty GeoDataFrame\n",
       "Columns: [osm_id, asset, na...   \n",
       "4                   {'l1': None, 'l2': {}, 'l3': {}}   \n",
       "\n",
       "                                             l1_trib  \\\n",
       "0  {'flood_DERP_RW_H_4326_2080430320': {2: (0, 0)...   \n",
       "1  {'flood_DERP_RW_H_4326_2080430320': 46107.8680...   \n",
       "2  {'flood_DERP_RW_H': 46107.86801530879, 'flood_...   \n",
       "3          osm_id asset         name gauge   elec...   \n",
       "4  {'l1': {0: 266240624.64660648}, 'l2': {}, 'l3'...   \n",
       "\n",
       "                                             l2_trib  \\\n",
       "0  {'flood_DERP_RW_H_4326_2080430320': {2: (0.0, ...   \n",
       "1  {'flood_DERP_RW_H_4326_2080430320': 0, 'flood_...   \n",
       "2  {'flood_DERP_RW_H': 0, 'flood_DERP_RW_M': 0, '...   \n",
       "3          osm_id asset                name gauge...   \n",
       "4  {'l1': {}, 'l2': {'flood_DERP_RW_H_4326_208043...   \n",
       "\n",
       "                                             l3_trib  \\\n",
       "0  {'flood_DERP_RW_H_4326_2080430320': {2: (0, 0)...   \n",
       "1  {'flood_DERP_RW_H_4326_2080430320': -104509.06...   \n",
       "2  {'flood_DERP_RW_H': -104509.06271837394, 'floo...   \n",
       "3  Empty GeoDataFrame\n",
       "Columns: [osm_id, asset, na...   \n",
       "4  {'l1': None, 'l2': {}, 'l3': {(4424116, 219651...   \n",
       "\n",
       "                                             l4_trib  \n",
       "0  {'flood_DERP_RW_H_4326_2080430320': {2: (0, 0)...  \n",
       "1  {'flood_DERP_RW_H_4326_2080430320': 46077.0756...  \n",
       "2  {'flood_DERP_RW_H': 46077.0756865045, 'flood_D...  \n",
       "3  Empty GeoDataFrame\n",
       "Columns: [osm_id, asset, na...  \n",
       "4                   {'l1': None, 'l2': {}, 'l3': {}}  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# report output dataframe\n",
    "output_df = pd.DataFrame.from_dict([direct_damages_adapted_dict, indirect_damages_adapted_dict, indirect_damages_adapted_full_dict, adapted_assets_dict, adaptation_costs])\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results for adaptation: baseline\n",
      "Saved results for adaptation: l1_trib\n",
      "Saved results for adaptation: l2_trib\n",
      "Saved results for adaptation: l3_trib\n",
      "Saved results for adaptation: l4_trib\n"
     ]
    }
   ],
   "source": [
    "# Save results\n",
    "# adapt_id= 'l1_trib_test'\n",
    "for adapt_id in adaptations.keys():\n",
    "    if not adapt_id in direct_damages_adapted_dict.keys():\n",
    "        continue\n",
    "    direct_damages_adapted_path = data_path / 'output' / f'adapted_direct_damages_{adapt_id}.pkl'\n",
    "    indirect_damages_adapted_path = data_path / 'output' / f'adapted_indirect_damages_{adapt_id}.pkl'\n",
    "    indirect_damages_adapted_full_path = data_path / 'output' / f'adapted_indirect_damages_full_{adapt_id}.pkl'\n",
    "    # adaptations_df_path = data_path / 'output' / f'adaptations_{adapt_id}.csv'\n",
    "    adapted_assets_path = data_path / 'output' / f'adapted_assets_{adapt_id}.pkl'\n",
    "    adaptation_costs_path = data_path / 'output' / f'adaptation_costs_{adapt_id}.pkl'\n",
    "\n",
    "    with open(direct_damages_adapted_path, 'wb') as f:\n",
    "        pickle.dump(direct_damages_adapted_dict[adapt_id], f)\n",
    "    with open(indirect_damages_adapted_path, 'wb') as f:\n",
    "        pickle.dump(indirect_damages_adapted_dict[adapt_id], f)\n",
    "    with open(indirect_damages_adapted_full_path, 'wb') as f:\n",
    "        pickle.dump(indirect_damages_adapted_full_dict[adapt_id], f)    \n",
    "    with open(adapted_assets_path, 'wb') as f:\n",
    "        pickle.dump(adapted_assets_dict[adapt_id], f)\n",
    "    with open(adaptation_costs_path, 'wb') as f:\n",
    "        pickle.dump(adaptation_costs[adapt_id], f)\n",
    "    print(f'Saved results for adaptation: {adapt_id}')\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ci_adapt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
